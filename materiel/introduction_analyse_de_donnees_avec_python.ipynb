{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à l'analyse de données avec Python (Pandas)\n",
    "\n",
    "*par [Antoine Mazieres](https://www.antonomase.fr/) et [Julie Pierson](https://letg.cnrs.fr/auteur470.html)*\n",
    "\n",
    "Ce tutoriel présente la bibliothèque [Pandas](https://pandas.pydata.org/) qui permet l’import dans Python de types de données très appréciés des statisticiens et des data scientists et l’utilisation de fonctions qui facilitent les analyses et les visualisations les plus courantes.\n",
    "\n",
    "Ensuite nous présenterons rapidement quelques bibliothèques supplémentaire qui s'intègrent particulièrement bien avec Pandas pour faire de l'apprentissage artificel ([scikit-learn](https://scikit-learn.org/stable/)), de l'analyse de réseaux ([networkx](https://networkx.github.io/)) et pour travailler avec des données géographiques ([geopandas](https://geopandas.org/)).\n",
    "\n",
    "Ce tutoriel n'a pas l'ambition de vous apprendre ces différentes techniques, mais plutôt de vous faire un tour d'horizon de ces outils et de ce qu'il est possible de faire. **Choisissez ce que vous voulez explorer pendant ces 2h30 d'atelier, il n'est nullement nécessaire d'essayer de faire toutes les sections. Prenez ce qui vous intéresse, faites ce qui est proposé ou commencez à explorer des cas d'utilisation qui correspondent davantage à votre futur usage de ces outils.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "### `DataFrame` et `Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # \"pd\" devient une abbréviation pour \"pandas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas permet d'utiliser des matrices avec plus d'aisance que la bibliothèque [NumPy](https://numpy.org/) (sur laquelle il est basé par ailleurs). Le type de données [`DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) permet de gérer facilement des noms de colonnes, d'observation et propose tout un tas de fonctions utiles et bien intégrées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Bob\": {\"age\": 18, \"taille\": 190},\n",
    "    \"Alice\": {\"age\": 19, \"taille\": 185}\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose\n",
    "df = df.T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean() # ou .median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un type de données comparable pour les vecteurs (~matrice avec une seule colonne) est [`Series`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [\"a\", \"b\", \"c\", \"d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si on sélectionne une colonne d'un DataFrame, cela devient une Series\n",
    "df['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importer et exporter des données\n",
    "\n",
    "Pandas est **très** pratique pour importer et exporter des données depuis/vers un grand nombre de format (CSV, JSON, EXCEL, HDF, SQL, PICKLE, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produit un ficher test.csv dans le répertoire courant\n",
    "df.to_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# afficher le contenu du fichier\n",
    "with open(\"./test.csv\") as fi:\n",
    "    for line in fi:\n",
    "        print(line.strip()) # .strip() enlève les sauts de ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import de ce fichier directement dans un DataFrame\n",
    "new_df = pd.read_csv(\"./test.csv\", index_col=0)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jouer avec un exemple\n",
    "\n",
    "Nous allons nous exercer sur un dataset sur environ 4000 films constitué dans l'idée d'étudier les inégalités de genre dans l'apparition à l'écran dans les films populaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe le fichier en indiquant que la première colonne représente l'index\n",
    "df = pd.read_csv(\"./datasets/genre_cinema.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affiche les premières lignes de la base de données\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affiche le nombre d'observations (lignes) et de variables (colonnes)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une rapide description des variables :\n",
    "\n",
    "- les chaines de caractères qui composent l'index, commençant par \"tt\", représentent l'ID du film sur IMDB. Par exemple : https://www.imdb.com/title/tt0381061/ pour le film \"Casino Royale\"\n",
    "\n",
    "- `parental_rating` : censure du film en fonction de l'âge du spectateur ([détails](https://en.wikipedia.org/wiki/Motion_Picture_Association_film_rating_system#:~:text=Rated%20G%3A%20General%20audiences%20%E2%80%93%20All,accompanying%20parent%20or%20adult%20guardian.))\n",
    "\n",
    "- `rating_count` : le nombre de personnes ayant voté sur IMDB pour attribuer une note au film.\n",
    "\n",
    "- `rating_value` : la note en question.\n",
    "\n",
    "- `runtime` : la durée du film en minutes.\n",
    "\n",
    "- `budget` : le budget du film, en dollars.\n",
    "\n",
    "- `wwgross` : *world wide gross*, la recette du film, en dollars\n",
    "\n",
    "- `bechdel_test` : une mesure de la représentation des femmes au cinéma ([détails](https://fr.wikipedia.org/wiki/Test_de_Bechdel)), composée de 3 conditions cumulatives : le fait qu'il y ait au moins deux femmes dans le film (1), qui se parlent (2), à propos d'autre chose que d'un homme (3). La valeur (0) indique que le film ne remplit aucune des conditions ([source](https://bechdeltest.com/)).\n",
    "\n",
    "- `female_face_ratio` : une estimation du ratio de visages de femmes qui apparaissent parmi toutes les apparitions de visages à l'écran.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quelques exemples de manipulation et de visualisation des données**\n",
    "\n",
    "Pour la visualisation, Pandas est contruit sur la bibliothèque [`MatPlotLib`](https://matplotlib.org/). Elle est réputée peu intuitive et Pandas contribue à rendre son usage plus simple.\n",
    "Il faut cependant importer le module :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer un raccourci \"plt\" pour le sous-module \"pyplot\" de matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici un tutoriel complet sur ce qu'offre Pandas en terme de visualisation : https://pandas.pydata.org/docs/user_guide/visualization.html\n",
    "\n",
    "Explorons ensemble quelques exemples :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observer la distribution d'une variable\n",
    "df['parental_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['parental_rating'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N'afficher que les films censuré \"R\"\n",
    "df[df['parental_rating'] == \"R\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N'afficher que les films censuré \"R\" qui ont une note IMDB > 7\n",
    "df[(df['parental_rating'] == \"R\") & (df['rating_value'] > 7)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regrouper les films par année en faisant la moyenne de leurs \"female_face_ratio\"\n",
    "df[['year', 'female_face_ratio']].groupby(['year']).mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser cette évolution\n",
    "df[['year', 'female_face_ratio']].groupby(['year']).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quelques exercices**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher des valeurs ou une figure qui apportent des éléments de réponse aux questions suivantes :\n",
    "\n",
    "- Quelle est la moyenne du `female_face_ratio` pour les films censurés `PG-13` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le code de votre réponse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- le `female_face_ratio` semble-t-il corrélé à la recette du film ? (indice : [`.plot.scatter()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.scatter.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le code de votre réponse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quelle est la proportion de films qui passent le Bechdel test par quartile de valeur des notes sur IMDB ? (indice : [`.qcut()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le code de votre réponse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À vous de jouer, essayer de révéler/visualiser quelque chose à partir de ce jeu de données !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoPandas\n",
    "\n",
    "Geopandas est un module Python qui permet d'afficher et de manipuler des données géographiques.\n",
    "\n",
    "Pour installer geopandas sur Mac et Linux, tapez la commande suivante dans un terminal : `python -m pip install geopandas`\n",
    "\n",
    "Pour windows, tapez les commandes suivantes, l'une après l'autre :\n",
    "\n",
    "```bash\n",
    "conda update conda\n",
    "conda update anaconda\n",
    "conda install -c conda-forge gdal\n",
    "conda install geopandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons ici à partir d'un tableau contenant une liste de villes avec leurs coordonnées, afficher ces villes, ajouter un fonds de carte, et joindre des données à ces villes pour en représenter la population sous forme d'une carte en cercles proportionnels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont dans un tableau au format CSV : rien de nouveau jusqu'ici !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcities = pd.read_csv(\"./datasets/ne_110m_populated_places_coord.csv\", index_col=0)\n",
    "dfcities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les latitudes et longitude des villes sont dans une même colonne **coordonnees**.\n",
    "\n",
    "La 1ère étape va consister à séparer ces coordonnées dans 2 colonnes différentes, afin de pouvoir ensuite facilement visualiser les villes sous forme de points.\n",
    "\n",
    "Pour cela, nous allons utiliser la fonction **split** (rappelez-vous !) en l'appliquant à toutes les valeurs de la colonne **coordonnees** pour créer 2 colonnes **latitude** et **longitude**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcities[['latitude','longitude']] = dfcities['coordonnees'].str.split(', ',expand=True)\n",
    "dfcities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut supprimer la colonne coordonnees devenue inutile :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcities = dfcities.drop(columns=['coordonnees'])\n",
    "dfcities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pouvoir que ce dataframe puisse être affiché sous forme de données géographiques, il faut le transformer en geodataframe.\n",
    "\n",
    "Ceci va y ajouter une colonne **geometry** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfcities = geopandas.GeoDataFrame(dfcities, geometry=geopandas.points_from_xy(dfcities['longitude'], dfcities['latitude']))\n",
    "gdfcities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant afficher les villes sous forme de points :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfcities.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rapide ! Mais on n'y voit pas grand chose. On peut paramétrer les symboles, les axes et beaucoup de choses avec le module matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetez un oeil ici pour avoir un aperçu : https://darribas.org/gds16/content/labs/lab_02.html\n",
    "\n",
    "Par exemple comme ceci :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'une figure et de ses axes\n",
    "f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "# ajout du geodataframe de villes\n",
    "gdfcities.plot(ax=ax, markersize=5, color=\"gray\")\n",
    "# suppression des axes\n",
    "ax.set_axis_off()\n",
    "# affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et en ajoutant un fond de carte :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un geodataframe avec les pays\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "# création d'une figure et de ses axes\n",
    "f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "# ajout du geodataframe de pays\n",
    "world.plot(ax=ax, facecolor=\"lightgray\", edgecolor=\"white\")\n",
    "# ajout du geodataframe de villes\n",
    "gdfcities.plot(ax=ax, markersize=5, color=\"black\")\n",
    "# suppression des axes\n",
    "ax.set_axis_off()\n",
    "# affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et si on veut joindre des données à ces points, par exemple de population ?\n",
    "\n",
    "Ca tombe bien, nous avons un fichier CSV qui contient des données de population pour chaque ville :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpop = pd.read_csv(\"./datasets/ne_pop_cities.csv\", index_col=0)\n",
    "dfpop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour rappel, la couche de villes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier de population possède la même colonne d'identifiant **ne_id** que la couche de villes : on va donc pouvoir les joindre grâce à cet identifiant, en utilisant merge :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfall = pd.merge(gdfcities, dfpop, left_on='ne_id', right_on='ne_id')\n",
    "gdfall.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a maintenant un seul fichier avec une colonne geometry permettant de localiser les villes, et une colonne pop_max avec la population de chaque ville.\n",
    "Et si on veut faire varier la surface de chaque point en fonction de la population, pour faire une carte en symboles proportionnels ?\n",
    "\n",
    "Rappelez-vous, pour ce type de carte, il faut faire varier la surface et non le rayon des cercles !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un geodataframe avec les pays\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "# création d'une figure et de ses axes\n",
    "f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "# ajout du geodataframe de pays\n",
    "world.plot(ax=ax, facecolor=\"lightgray\", edgecolor=\"white\")\n",
    "# ajout du geodataframe de villes\n",
    "import numpy as np\n",
    "gdfall.plot(ax=ax, color=\"black\", markersize=np.sqrt(gdfall['pop_max']))\n",
    "# suppression des axes\n",
    "ax.set_axis_off()\n",
    "# affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mmmh, on n'y voit pas grand chose... Voyons déjà le détail de la formule utilisée :\n",
    "\n",
    "`import numpy as np`\n",
    "\n",
    "permet l'import du module numpy dont nous allons utiliser la fonction **sqrt** : racine carrée.\n",
    "\n",
    "`gdfall.plot(ax=ax, color=\"black\", markersize=np.sqrt(gdfall['pop_max']))`\n",
    "\n",
    "Cette ligne affiche les villes en faisant varier la taille (le diamètre) des cercles en fonction de la racine carrée de la population.\n",
    "\n",
    "Pour y voir un peu plus clair, on peut recommencer en réduisant la taille de tous les cercles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'une figure et de ses axes\n",
    "f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "# ajout du geodataframe de pays\n",
    "world.plot(ax=ax, facecolor=\"lightgray\", edgecolor=\"white\")\n",
    "# ajout du geodataframe de villes\n",
    "import numpy as np\n",
    "gdfall.plot(ax=ax, color=\"black\", markersize=np.sqrt(gdfall['pop_max'])/30)\n",
    "# suppression des axes\n",
    "ax.set_axis_off()\n",
    "# affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec un peu de transparence et de couleur pour mieux voir les superpositions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'une figure et de ses axes\n",
    "f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "# ajout du geodataframe de pays\n",
    "world.plot(ax=ax, facecolor=\"lightgray\", edgecolor=\"white\")\n",
    "# ajout du geodataframe de villes\n",
    "import numpy as np\n",
    "gdfall.plot(ax=ax, color=\"blue\", alpha=.7, linewidth=1, edgecolor=\"white\", markersize=np.sqrt(gdfall['pop_max'])/20)\n",
    "# suppression des axes\n",
    "ax.set_axis_off()\n",
    "# affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et en affichant les plus petits cercles devant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'une figure et de ses axes\n",
    "f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "# ajout du geodataframe de pays\n",
    "world.plot(ax=ax, facecolor=\"lightgray\", edgecolor=\"white\")\n",
    "# ajout du geodataframe de villes\n",
    "import numpy as np\n",
    "gdfallsort = gdfall.sort_values('pop_max', ascending=False)\n",
    "gdfallsort.plot(ax=ax, color=\"blue\", alpha=.7, linewidth=1, edgecolor=\"white\", markersize=np.sqrt(gdfallsort['pop_max'])/20)\n",
    "# suppression des axes\n",
    "ax.set_axis_off()\n",
    "# affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qui nous permet d'avoir un premier aperçu de nos données !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse de réseau ([networkx](https://networkx.github.io/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour nous initier à l'analyse de réseau, nous allons utiliser la bibliothèque [NetworkX](https://networkx.github.io/).\n",
    "\n",
    "Chaque film de la base de données utilisée précédemment possède une variable `genre` qui contient une liste de type de film (\"comédie\", \"romance\", etc.). Nous allons essayer de faire un graph des co-occurrences entre ces genres de films, c'est à dire observer la manière dont ils ont tendance à apparaitre ensemble.\n",
    "\n",
    "Pour ce faire nous utiliserons une version simplifiée de ces données disponible @ `datasets/genres,csv` dont voici les premières lignes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open(\"./datasets/genres.csv\") as fi:\n",
    "    for line in fi:\n",
    "        if i > 5:\n",
    "            break\n",
    "        print(line.strip())\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declarer le graph\n",
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer les noeuds\n",
    "noeuds = set()\n",
    "with open(\"./datasets/genres.csv\") as fo:\n",
    "    for line in fo:\n",
    "        for n in line.strip().split(\",\")[1:]:\n",
    "            noeuds.add(n)\n",
    "\n",
    "for n in noeuds:\n",
    "    G.add_node(n)\n",
    "\n",
    "G.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créér les liens\n",
    "with open(\"./datasets/genres.csv\") as fo:\n",
    "    for line in fo:\n",
    "        for n in itertools.combinations(line.strip().split(\",\")[1:], 2):\n",
    "            G.add_edge(n[0], n[1])\n",
    "            \n",
    "list(G.edges)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "nx.draw_networkx(G, with_labels=True, font_size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est moche et ça ne dit pas grand chose ! Tous les liens, ou presque, sont présents, ce qui empêche de visualiser leur fréquence.\n",
    "\n",
    "Essayons de mieux faire en attribuant à chaque lien un \"poids\" qui représentera cette fréquence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_edges = {}\n",
    "\n",
    "with open(\"./datasets/genres.csv\") as fo:\n",
    "    for line in fo:\n",
    "        for n in itertools.combinations(line.strip().split(\",\")[1:], 2):\n",
    "            edge = tuple(sorted(n))\n",
    "            if edge not in better_edges:\n",
    "                better_edges[edge] = 1\n",
    "            else:\n",
    "                better_edges[edge] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for edge, frequence in better_edges.items():\n",
    "    G.add_edge(edge[0], edge[1])\n",
    "    G.edges[edge[0], edge[1]]['weight'] = frequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.edges['Action', 'Adventure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "edges = G.edges()\n",
    "weights = [G[u][v]['weight']*.005 for u,v in edges]\n",
    "nx.draw(G,  \n",
    "        width=list(weights),\n",
    "        with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe de nombreuses options de visualisations comme la taille et coloration des noeuds par exemple ou l'algorithme de spatialisation du réseau. Networkx vous permet d'en explorer beaucoup, mais beaucoup d'utilisateurs aiment se tourner vers [Gephi](https://gephi.org/) lorsqu'il s'agit de tester de nombreuses options visuelles. NetworkX permet d'exporter facilement votre Graph vers le format de fichier de Gephi :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, \"./test.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant importer le fichier `test.gexf` fans Gephi et modifier/analyser le graph de manière interactive.\n",
    "\n",
    "Un usage plus fréquent de NetworkX est l'utilisation des algorithmes (détection de communauté, clique, etc.) et de mesure (centralité, distribution de degré, etc.). Vous pouvez trouver de nombreux éléments et exemples ici : https://networkx.github.io/documentation/stable/reference/index.html\n",
    "\n",
    "À vous de jouer et de découvrir ou approfondir les éléments qui vous seront le plus utiles !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage artificiel ([scikit-learn](https://scikit-learn.org/stable/))\n",
    "\n",
    "Avec Python, l'apprentissage artificiel est rendu assez facile avec la bibliothèque [scikit-learn](https://scikit-learn.org/stable/). Nous allons rapidement passer sur quelques scénarios d'usage classique du *machine learning*, à savoir : la réduction de dimensionnalité, le regroupement et la classification.\n",
    "\n",
    "Pour ce faire, nous allons travailler avec la même base de données mais avec un nombre réduit de variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasets/genre_cinema.csv\", index_col=0)\n",
    "df_min = df[['rating_count', 'rating_value', 'runtime', 'wwgross', 'female_face_ratio']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réduction de dimensionalité\n",
    "\n",
    "Pour cet exemple nous allons utiliser une analyse en composante principale pour représenter les données en seulement deux dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliser le dataset\n",
    "df_norm = (df_min - df_min.mean()) / df_min.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculer la PCA\n",
    "pca = PCA(n_components='mle')\n",
    "pca_res = pca.fit_transform(df_norm.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observer la variance expliquée par les composantes\n",
    "ebouli = pd.Series(pca.explained_variance_ratio_)\n",
    "ebouli.plot(kind='bar', title=\"Ebouli des valeurs propres\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observer les corrélations entre variables et composantes\n",
    "# Une excellente explication du cercle des corrélations : https://youtu.be/2UFiMvXvdZ4?t=192\n",
    "\n",
    "def circleOfCorrelations(pc_infos, ebouli):\n",
    "    plt.Circle((0,0), radius=10, color='g', fill=False)\n",
    "    circle1=plt.Circle((0,0),radius=1, color='g', fill=False)\n",
    "    fig = plt.gcf()\n",
    "    fig.gca().add_artist(circle1)\n",
    "    for idx in range(len(pc_infos[\"PC-0\"])):\n",
    "        x = pc_infos[\"PC-0\"][idx]\n",
    "        y = pc_infos[\"PC-1\"][idx]\n",
    "        plt.plot([0.0,x],[0.0,y],'k-')\n",
    "        plt.plot(x, y, 'rx')\n",
    "        plt.annotate(pc_infos.index[idx], xy=(x,y))\n",
    "    plt.xlabel(\"PC-0 (%s%%)\" % str(ebouli[0])[:4].lstrip(\"0.\"))\n",
    "    plt.ylabel(\"PC-1 (%s%%)\" % str(ebouli[1])[:4].lstrip(\"0.\"))\n",
    "    plt.xlim((-1,1))\n",
    "    plt.ylim((-1,1))\n",
    "    plt.title(\"Circle of Correlations\")\n",
    "\n",
    "\n",
    "coef = np.transpose(pca.components_)\n",
    "cols = ['PC-'+str(x) for x in range(len(ebouli))]\n",
    "pc_infos = pd.DataFrame(coef, columns=cols, index=df_norm.columns)\n",
    "circleOfCorrelations(pc_infos, ebouli)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regroupement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utiliser l'algorithme des K-moyennes, mais la plupart des procédures de regroupement sont disponibles sur scikit-learn : https://scikit-learn.org/stable/modules/clustering.html#clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clusters = 3\n",
    "\n",
    "# Calcul des centroides\n",
    "centroids, _ = cluster.vq.kmeans(df_min.values, nb_clusters, iter=100)\n",
    "\n",
    "idx, _ = cluster.vq.vq(df_min.values, centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons visualiser ces clusters en utilisant les deux composantes principales révélées par la PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(pca_res, columns=cols)\n",
    "\n",
    "for clust in set(idx):\n",
    "    colors = list(\"bgrcmyk\")\n",
    "    plt.scatter(dat[\"PC-0\"][idx==clust],dat[\"PC-1\"][idx==clust],c=colors[clust])\n",
    "plt.xlabel(\"PC-0 (%s%%)\" % str(ebouli[0])[:4].lstrip(\"0.\"))\n",
    "plt.ylabel(\"PC-1 (%s%%)\" % str(ebouli[1])[:4].lstrip(\"0.\"))\n",
    "plt.title(\"K-Means / PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant un algorithme de classification classique, les arbres de décision, nous allons essayer de classifier les films censurés \"R\" des autres.\n",
    "\n",
    "De nombreux autres algorithmes d'apprentissage supervisé sont disponibles sur scikit-learn : https://scikit-learn.org/stable/supervised_learning.html#supervised-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# déclarer le classifieur\n",
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construction du modèle\n",
    "clf = clf.fit(df_min.values, (df['parental_rating'] == \"R\").astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation du modèle\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "tree.plot_tree(clf, max_depth=2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
